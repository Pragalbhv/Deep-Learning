{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34789f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2315322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d99502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.where(x >= 0, \n",
    "                        x, \n",
    "                        0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94c5e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(activation):#maybe getderivatives here iteself ?\n",
    "    def sigmoid(x):\n",
    "        return np.where(x >= 0, \n",
    "                        1 / (1 + np.exp(-x)), \n",
    "                        np.exp(x) / (1 + np.exp(x)))\n",
    "    def softmax(x):\n",
    "        z=x-np.max(x,axis=0)\n",
    "        return np.exp(z)/np.sum(np.exp(z),axis=0)\n",
    "    def relu(x):\n",
    "        rel=np.where(x >= 0, \n",
    "                            x, \n",
    "                            0)\n",
    "        return rel\n",
    "    if activation=='sigmoid':\n",
    "        return sigmoid\n",
    "    elif activation=='softmax':\n",
    "        return softmax\n",
    "    elif activation== 'tanh':\n",
    "        return np.tanh\n",
    "    elif activation== 'relu':\n",
    "        return relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f384261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation_derivative(activation):#maybe getderivatives here iteself ?\n",
    "    def sigmoid_d(x):\n",
    "        sig= np.where(x >= 0, 1 / (1 + np.exp(-x)), np.exp(x) / (1 + np.exp(x)))\n",
    "        return sig*(1-sig)\n",
    "    def softmax_d(x):\n",
    "        z=x-np.max(x,axis=0)\n",
    "        soft=np.exp(z)/np.sum(np.exp(z),axis=0)\n",
    "        return soft*(1-soft)\n",
    "    def tanh_d(x):\n",
    "        return 1-np.tanh(x)**2\n",
    "    def relu_d(x):\n",
    "        return np.where(x >= 0, \n",
    "                            1, \n",
    "                            0)\n",
    "    \n",
    "    if activation=='sigmoid':\n",
    "        return sigmoid_d\n",
    "    elif activation=='softmax':\n",
    "        '''\n",
    "        need to think more, not required for backprop as we look directly at dL/da_l\n",
    "        But still, for the sake of completeness, and if user wants softmax in the middle?\n",
    "        d S(x_i) /d x_j= S(x_i)*(kronecker delta_i,j -S(x_j))\n",
    "        But we care about only dh_k,j/da_k,j So no need to implement d S(x_i) /d x_j\n",
    "        d S(x_i) /d x_i should suffice\n",
    "        so we get array of [ d S(x_1) /d x_1, d S(x_2) /d x_2, ....]\n",
    "        \n",
    "        For MSE loss after softmax, we need cross terms...\n",
    "        '''\n",
    "        \n",
    "        return softmax_d\n",
    "    elif activation=='tanh':\n",
    "        return tanh_d\n",
    "    elif activation=='relu':\n",
    "        return relu_d\n",
    "    assert(activation=='relu'or activation=='tanh'or activation=='sigmoid' or activation=='softmax'), 'Must be \\'relu\\'or \\'tanh\\' or \\'sigmoid\\' or \\'softmax\\' '\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c0621d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(loss='cross-entropy'):\n",
    "    \n",
    "   \n",
    "    \n",
    "    safety=1e-30    \n",
    "    def crossentropy(P,Q):\n",
    "        assert(P.shape==Q.shape), \"Inputs must be of same shape\"\n",
    "\n",
    "        return np.sum([-np.dot(P[:,i],np.log2(Q[:,i]+safety)) for i in range(P.shape[1])])\n",
    "    def SE(P,Q):\n",
    "        assert(P.shape==Q.shape), \"Inputs must be of same shape\"\n",
    "\n",
    "        return np.sum(np.square(P-Q))\n",
    "    \n",
    "    if loss==\"SE\":\n",
    "        return SE\n",
    "    return crossentropy\n",
    "    \n",
    "    \n",
    "      \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a254663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_derivative(loss):\n",
    "    def SE_d(y_in,y_pred_in):\n",
    "        '''\n",
    "        derivative of MSE after softmax is used to get probabs from a_L:\n",
    "        We need indicator because the all terms of y_true are required unlike cross-entropy where only y_pred[l] is required\n",
    "        Thus transforming the stacked indicator to y_true, not here...\n",
    "        \n",
    "        '''\n",
    "\n",
    "        def indicator(i,j):\n",
    "                if i==j:\n",
    "                    return 1\n",
    "                return 0\n",
    "\n",
    "\n",
    "        assert(y_in.shape[0]==y_pred_in.shape[0]),\"Inputs must contain same number of examples\"\n",
    "\n",
    "        y=y_in.ravel()\n",
    "        y_pred=y_pred_in.ravel()\n",
    "\n",
    "\n",
    "        return np.array([\n",
    "            [2*np.sum([(y_pred[i]-y[i])*y[i]*(indicator(i,j) - y_pred[j]) for i in range(y.shape[0])])]\n",
    "            for j in range(len(y))\n",
    "        ])    \n",
    "   \n",
    "    \n",
    "        \n",
    "    def crossentropy_d(y,y_pred):\n",
    "        \n",
    "\n",
    "        return -(y-y_pred)\n",
    "    \n",
    "    \n",
    "    if loss==\"cross-entropy\":\n",
    "        return crossentropy_d\n",
    "    return SE_d\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c48942c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer:\n",
    "    def __init__(self,input_size,output_size,activation='sigmoid',batch_size=2,type_='random'):\n",
    "            \n",
    "        ''' \n",
    "        output size number of neurons i\n",
    "        input size j\n",
    "        \n",
    "        '''\n",
    "        assert(type_=='random'or type_=='xavier'or type_=='glorot' or type_=='He' ), 'Must be \\'random\\'or \\'xavier\\' or \\'glorot\\' or \\'He\\' '\n",
    "        \n",
    "        if type_=='random':\n",
    "            scale=0.01\n",
    "            self.W=np.random.randn(output_size,input_size)*scale #size ixj\n",
    "            self.b=np.zeros((output_size,1))         #size i\n",
    "            \n",
    "        elif type_=='xavier' or type_=='glorot':\n",
    "            # Xavier Uniform\n",
    "            r=np.sqrt(6/(input_size+output_size))\n",
    "            self.W=np.random.uniform(-r,r,(output_size,input_size))\n",
    "            self.b=np.zeros((output_size,1))\n",
    "            \n",
    "        else:#He\n",
    "            self.W= np.random.randn(output_size,input_size)*np.sqrt(2/input_size)\n",
    "            self.b=np.zeros((output_size,1))\n",
    "            \n",
    "                \n",
    "            \n",
    "            \n",
    "            \n",
    "        self.a=np.zeros((output_size,batch_size))          #size i\n",
    "        self.h=np.zeros((output_size,batch_size))         #size i\n",
    "        self.g=get_activation(activation)\n",
    "        \n",
    "        self.d_a=np.zeros((output_size,batch_size))\n",
    "        self.d_h=np.zeros((output_size,batch_size))\n",
    "        self.d_W=np.zeros((output_size,input_size))\n",
    "        self.d_b=np.zeros((output_size,1))\n",
    "        self.d_g=get_activation_derivative(activation)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        self.a=self.b+np.matmul(self.W,inputs)\n",
    "        self.h=self.g(self.a)\n",
    "        return self.h\n",
    "    def reset(self):\n",
    "        self.d_a=np.zeros(np.shape(self.d_a))\n",
    "        self.d_h=np.zeros(np.shape(self.d_h))\n",
    "        self.d_W=np.zeros(np.shape(self.d_W))\n",
    "        self.d_b=np.zeros(np.shape(self.d_b))\n",
    "        \n",
    "    def hard_set(self,W,b):#hardsets the weight. useful for debugging\n",
    "        self.W=W\n",
    "        self.b=b\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06f18d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self,X_size,Y_size,hidden_layer_sizes=[4],hidden_layer_activations=['relu'],hidden_layer_initializations=['random'],loss='cross-entropy',lamdba_m=0,batch_size=4):\n",
    "        '''\n",
    "        '''   \n",
    "        \n",
    "        self.input_size=X_size\n",
    "        self.output_size=Y_size\n",
    "        self.hidden_layer_sizes=hidden_layer_sizes\n",
    "        self.layers=[]\n",
    "        self.batch_size=batch_size\n",
    "        \n",
    "        prev_size=self.input_size\n",
    "        for size,activation,inits in zip(hidden_layer_sizes,hidden_layer_activations,hidden_layer_initializations):\n",
    "            self.layers.append(layer(prev_size,size,activation,batch_size,inits))\n",
    "            prev_size=size\n",
    "        self.layers.append(layer(size,self.output_size,'softmax',batch_size,'xavier'))\n",
    "        \n",
    "        self.loss=get_loss(loss)#without regularization term\n",
    "        self.loss_d=get_loss_derivative(loss)\n",
    "        self.lamdba_m=lamdba_m #we shall pass lambda/m to this, where m is patch size\n",
    "        \n",
    "    def forward(self,x):\n",
    "        output=x\n",
    "        \n",
    "        for layer in  self.layers:\n",
    "            output=layer.forward(output)  \n",
    "        return output\n",
    "    \n",
    "    def backward(self,x,y,y_pred):\n",
    "        # self.layers[-1].d_h is not needed as d_h is used to calculate d_a and self.layers[-1].h is softmax\n",
    "        self.layers[-1].d_a=self.loss_d(y,y_pred)\n",
    "            \n",
    "        \n",
    "        \n",
    "        for idx in range(len(self.layers)-1,0,-1): #goes from L->2, for l=1 we do outside\n",
    "            \n",
    "            \n",
    "            #compute gradient wrt parameters\n",
    "            self.layers[idx].d_W=np.dot(self.layers[idx].d_a,np.transpose(self.layers[idx-1].h))+self.lamdba_m*self.layers[idx].W\n",
    "            self.layers[idx].d_b=np.sum(self.layers[idx].d_a,axis=1,keepdims=True)\n",
    "            \n",
    "            #compute gradient wrt layer below -- will help in next layer iter\n",
    "            self.layers[idx-1].d_h=np.matmul(np.transpose(self.layers[idx].W),self.layers[idx].d_a)\n",
    "            \n",
    "            #compute gradient -- element wise multiplivation, derivative of the activation function of layer idx-1\n",
    "            self.layers[idx-1].d_a=self.layers[idx-1].d_h*self.layers[idx-1].d_g(self.layers[idx-1].a)\n",
    "        assert(idx-1==0)\n",
    "                        \n",
    "        self.layers[0].d_W=np.dot(self.layers[0].d_a,np.transpose(x))+self.lamdba_m*self.layers[0].W\n",
    "        self.layers[0].d_b=np.sum(self.layers[0].d_a,axis=1,keepdims=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def predict(self,Xtest):\n",
    "        \n",
    "        return self.forward(Xtest)\n",
    "    \n",
    "        \n",
    "        \n",
    "                    \n",
    "                \n",
    "                \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec5a1ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class optimizers:\n",
    "    def __init__(self,X_size,Y_size,hidden_layer_sizes=[4],hidden_layer_activations=['relu'],hidden_layer_initializations=['He'],\n",
    "                 loss='cross-entropy',optimizer='adam',lamdba=0,batch_size=1,epochs=10,eta=1e-3):\n",
    "\n",
    "        self.batch_size=batch_size\n",
    "        self.epochs=epochs\n",
    "        self.train_loss=[]\n",
    "        self.val_loss=[]\n",
    "        self.model=Model(X_size,Y_size,hidden_layer_sizes,hidden_layer_activations,hidden_layer_initializations,loss,lamdba_m=lamdba/self.batch_size,batch_size=self.batch_size)\n",
    "        self.learning_rate=eta\n",
    "        self.optimizer=optimizer\n",
    "        \n",
    "        \n",
    "    def iterate(self,updator,X,Y,Xval,Yval):\n",
    "        reminder=X.shape[1]%self.batch_size #uneven batch size\n",
    "        for t in tqdm(range(self.epochs)):\n",
    "            for i in range(0,np.shape(X)[1]-self.batch_size,self.batch_size):\n",
    "                x=X[:,i:i+self.batch_size]\n",
    "                y=Y[:,i:i+self.batch_size]\n",
    "                y_pred=self.model.forward(x)\n",
    "    \n",
    "    \n",
    "                self.model.backward(x,y,y_pred)\n",
    "                updator(t)\n",
    "\n",
    "            if reminder:\n",
    "\n",
    "                x=np.hstack((X[:,i+self.batch_size:],X[:,:reminder]))\n",
    "                y=np.hstack((Y[:,i+self.batch_size:],Y[:,:reminder]))\n",
    "                y_pred=self.model.forward(x)\n",
    "                self.model.backward(x,y,y_pred)\n",
    "                updator(t)\n",
    "            self.loss_calc(X,Y,Xval,Yval) \n",
    "            \n",
    "    def loss_calc(self,X,Y,Xval,Yval):\n",
    "            regularization=1/2*self.model.lamdba_m*np.sum([np.sum(layer.W**2) for layer in self.model.layers])\n",
    "            self.train_loss.append((self.model.loss(Y,self.model.predict(X))+regularization)/X.shape[1])\n",
    "            self.val_loss.append(self.model.loss(Yval,self.model.predict(Xval))/Xval.shape[1])\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    def batch_gradient_descent(self,traindat,testdat):\n",
    "        \n",
    "        '''\n",
    "        Mini-Batch Gradient Descent\n",
    "        at batchsize=1, behaves like sgd, batchsize=np.shape(X)[1], behaves as gd\n",
    "        eta is the learning rate\n",
    "        '''\n",
    "        X,Y=traindat\n",
    "        \n",
    "        Xval,Yval=testdat\n",
    "        \n",
    "        def update_batch(_):\n",
    "            for layer in self.model.layers:\n",
    "                layer.W=layer.W-self.learning_rate*layer.d_W\n",
    "                layer.b=layer.b-self.learning_rate*layer.d_b\n",
    " \n",
    "        \n",
    "\n",
    "        updator=update_batch\n",
    "        self.iterate(updator,X,Y,Xval,Yval)\n",
    "\n",
    "            \n",
    "    def momentum(self,traindat,testdat,beta=0.9):\n",
    "        ''''''\n",
    "        \n",
    "        X,Y=traindat\n",
    "        \n",
    "        Xval,Yval=testdat\n",
    "        u_W=[np.zeros(np.shape(layer.d_W)) for layer in self.model.layers]\n",
    "        u_b=[np.zeros(np.shape(layer.d_b)) for layer in self.model.layers]\n",
    "        \n",
    "        def update_mom(_):\n",
    "            for i in range(len(self.model.layers)):\n",
    "                layer=self.model.layers[i]\n",
    "                u_W[i]=beta*u_W[i]+layer.d_W\n",
    "                u_b[i]=beta*u_b[i]+layer.d_b\n",
    "                layer.W=layer.W-self.learning_rate*u_W[i]\n",
    "                layer.b=layer.b-self.learning_rate*u_b[i]\n",
    "        \n",
    "        updator=update_mom\n",
    "        self.iterate(updator,X,Y,Xval,Yval)\n",
    "            \n",
    "\n",
    "    def rmsprop(self,traindat,testdat,beta=0.9,epsilon=1e-10):\n",
    "        ''''''\n",
    "        X,Y=traindat\n",
    "        \n",
    "        Xval,Yval=testdat\n",
    "        \n",
    "        v_W=[np.zeros(np.shape(layer.d_W)) for layer in self.model.layers]\n",
    "        v_b=[np.zeros(np.shape(layer.d_b)) for layer in self.model.layers]\n",
    "        \n",
    "        def update_rms(_):\n",
    "                for i in range(len(self.model.layers)):                 \n",
    "                    layer=self.model.layers[i]\n",
    "                    v_W[i]=beta*v_W[i]+(1-beta)*layer.d_W**2\n",
    "                    v_b[i]=beta*v_b[i]+(1-beta)*layer.d_b**2\n",
    "                    layer.W=layer.W-(self.learning_rate/np.sqrt(v_W[i]+epsilon))*layer.d_W\n",
    "                    layer.b=layer.b-(self.learning_rate/np.sqrt(v_b[i]+epsilon))*layer.d_b\n",
    "\n",
    "\n",
    "\n",
    "        updator=update_rms\n",
    "        self.iterate(updator,X,Y,Xval,Yval)\n",
    "            \n",
    "    def Adam(self,traindat,testdat,beta1=0.9, beta2=0.999,epsilon=1e-10):\n",
    "        ''''''\n",
    "        X,Y=traindat\n",
    "        \n",
    "        Xval,Yval=testdat\n",
    "        \n",
    "        m_W=[np.zeros(np.shape(layer.d_W)) for layer in self.model.layers]\n",
    "        v_W=[np.zeros(np.shape(layer.d_W)) for layer in self.model.layers]\n",
    "        m_b=[np.zeros(np.shape(layer.d_b)) for layer in self.model.layers]\n",
    "        v_b=[np.zeros(np.shape(layer.d_b)) for layer in self.model.layers]\n",
    "        \n",
    "        def update_adam(t):\n",
    "            for i in range(len(self.model.layers)):\n",
    "                layer=self.model.layers[i]\n",
    "                #updating momentum, velocity\n",
    "                m_W[i]=beta1*m_W[i]+(1-beta1)*layer.d_W\n",
    "                m_b[i]=beta1*m_b[i]+(1-beta1)*layer.d_b\n",
    "\n",
    "                v_W[i]=beta2*v_W[i]+(1-beta2)*layer.d_W**2\n",
    "                v_b[i]=beta2*v_b[i]+(1-beta2)*layer.d_b**2\n",
    "\n",
    "                m_W_hat=m_W[i]/(1-np.power(beta1,t+1))\n",
    "                m_b_hat=m_b[i]/(1-np.power(beta1,t+1))\n",
    "                v_W_hat=v_W[i]/(1-np.power(beta2,t+1))\n",
    "                v_b_hat=v_b[i]/(1-np.power(beta2,t+1))\n",
    "\n",
    "\n",
    "\n",
    "                layer.W=layer.W-(self.learning_rate*m_W_hat)/(np.sqrt(v_W_hat)+epsilon)\n",
    "                layer.b=layer.b-(self.learning_rate*m_b_hat)/(np.sqrt(v_b_hat)+epsilon)\n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        updator=update_adam\n",
    "        self.iterate(updator,X,Y,Xval,Yval)\n",
    "    \n",
    "    def NAG(self,traindat,testdat,beta=0.9):\n",
    "        \n",
    "        ''''''\n",
    "        \n",
    "        X,Y=traindat\n",
    "        \n",
    "        \n",
    "        Xval,Yval=testdat\n",
    "        \n",
    "        m_W=[np.zeros(np.shape(layer.d_W)) for layer in self.model.layers]\n",
    "        m_b=[np.zeros(np.shape(layer.d_b)) for layer in self.model.layers]\n",
    "        def update_nag(_):\n",
    "            for i in range(len(self.model.layers)):\n",
    "                layer=self.model.layers[i]\n",
    "                m_W[i]=beta*m_W[i]+self.learning_rate*layer.d_W\n",
    "                m_b[i]=beta*m_b[i]+self.learning_rate*layer.d_b\n",
    "\n",
    "\n",
    "                layer.W=layer.W-(beta*m_W[i]+self.learning_rate*layer.d_W[i])\n",
    "                layer.b=layer.b-(beta*m_b[i]+self.learning_rate*layer.d_b[i])\n",
    "            \n",
    "        updator=update_nag\n",
    "        self.iterate(updator,X,Y,Xval,Yval)\n",
    "    \n",
    "    def NAdam(self,traindat,testdat,beta1=0.9, beta2=0.999,epsilon=1e-10):\n",
    "        ''''''\n",
    "        \n",
    "        X,Y=traindat\n",
    "        \n",
    "        Xval,Yval=testdat\n",
    "        \n",
    "        m_W=[np.zeros(np.shape(layer.d_W)) for layer in self.model.layers]\n",
    "        v_W=[np.zeros(np.shape(layer.d_W)) for layer in self.model.layers]\n",
    "        m_b=[np.zeros(np.shape(layer.d_b)) for layer in self.model.layers]\n",
    "        v_b=[np.zeros(np.shape(layer.d_b)) for layer in self.model.layers]\n",
    "        \n",
    "        def update_nadam(t):\n",
    "            for i in range(len(self.model.layers)):\n",
    "                layer=self.model.layers[i]\n",
    "                #updating momentum, velocity\n",
    "                m_W[i]=beta1*m_W[i]+(1-beta1)*layer.d_W\n",
    "                m_b[i]=beta1*m_b[i]+(1-beta1)*layer.d_b\n",
    "\n",
    "                v_W[i]=beta2*v_W[i]+(1-beta2)*layer.d_W**2\n",
    "                v_b[i]=beta2*v_b[i]+(1-beta2)*layer.d_b**2\n",
    "\n",
    "                m_W_hat=m_W[i]/(1-np.power(beta1,t+1))\n",
    "                m_b_hat=m_b[i]/(1-np.power(beta1,t+1))\n",
    "                v_W_hat=v_W[i]/(1-np.power(beta2,t+1))\n",
    "                v_b_hat=v_b[i]/(1-np.power(beta2,t+1))\n",
    "\n",
    "\n",
    "\n",
    "                layer.W=layer.W-(self.learning_rate/(np.sqrt(v_W_hat)+epsilon))*\\\n",
    "                (beta1*m_W_hat+((1-beta1)/(1-np.power(beta1,t+1)))*layer.d_W)\n",
    "                layer.b=layer.b-(self.learning_rate/(np.sqrt(v_b_hat)+epsilon))*\\\n",
    "                (beta1*m_b_hat+((1-beta1)/(1-np.power(beta1,t+1)))*layer.d_b)            \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        updator=update_nadam\n",
    "        self.iterate(updator,X,Y,Xval,Yval)\n",
    "\n",
    "    def run(self,traindat,testdat,beta=0.9,beta1=0.9, beta2=0.999,epsilon=1e-10):\n",
    "        \"sgd\", \"batch\", \"momentum\", \"nag\", \"rmsprop\", \"adam\", \"nadam\"\n",
    "        \n",
    "        if self.optimizer==\"batch\":\n",
    "            self.batch_gradient_descent(self,traindat,testdat)\n",
    "            \n",
    "        elif self.optimizer==\"sgd\":\n",
    "            assert(self.batch_size==1), \"Batch size should be 1 for stochastic gradient descent\"\n",
    "            self.batch_gradient_descent(self,traindat,testdat)\n",
    "            \n",
    "        elif self.optimizer==\"momentum\":\n",
    "            self.momentum(traindat,testdat,beta)\n",
    "            \n",
    "            \n",
    "        elif self.optimizer==\"nag\":\n",
    "            self.NAG(traindat,testdat,beta)\n",
    "            \n",
    "            \n",
    "        elif self.optimizer==\"rmsprop\":\n",
    "            self.rmsprop(traindat,testdat,beta=0.9,epsilon=1e-10)\n",
    "            \n",
    "        elif self.optimizer==\"adam\":\n",
    "            self.Adam(traindat,testdat,beta1=0.9, beta2=0.999,epsilon=1e-10)\n",
    "\n",
    "            \n",
    "            \n",
    "        elif self.optimizer==\"nadam\":\n",
    "            self.NAdam(traindat,testdat,beta1=0.9, beta2=0.999,epsilon=1e-10)\n",
    "\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            print(\"Invalid optimizer name \"+ self.optimizer)\n",
    "            return(0)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cda233",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d78258c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 23:08:05.847615: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-16 23:08:05.926639: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-16 23:08:05.943471: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-16 23:08:06.220185: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-16 23:08:06.220230: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-16 23:08:06.220233: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "\n",
    "# np.random.seed(42)#sets a seed, used for reproducability\n",
    "\n",
    "def one_hot(inarray): #converts to one hot encoding\n",
    "    outarray = np.zeros((inarray.size, inarray.max() + 1))\n",
    "    outarray[np.arange(inarray.size), inarray] = 1\n",
    "    return outarray\n",
    "\n",
    "def Preprocess(X,y):\n",
    "      \n",
    "    '''Unrolls X,y, rehsapes into column vectors, one hots y'''\n",
    "    assert(X.shape[0]==y.shape[0]),\"Inputs must contain same number of examples, stored in rows\" #checks if same dim\n",
    "    \n",
    "    X_processed=np.reshape(X,(X.shape[0],784))/255\n",
    "    X_processed=X_processed.T\n",
    "    y_processed=one_hot(y).T\n",
    "    return np.array(X_processed),y_processed\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "Xtest,ytest=Preprocess(X_test,y_test)\n",
    "\n",
    "# def tran_val_split(X,y,split=0.1):\n",
    "#     assert(X.shape[1]==y.shape[1]), \"Inputs must contain same number of examples, stored in columns\"# as vectors are now stored in cols, do check if no of elemnts are equal\n",
    "#     len_split=int(np.shape(X)[1]*split)\n",
    "#     X_val=X[:,:len_split]\n",
    "#     y_val=y[:,:len_split]\n",
    "    \n",
    "#     X_train=X[:,len_split:]\n",
    "#     y_train=y[:,len_split:]\n",
    "    \n",
    "#     return (X_train,y_train),(X_val,y_val)\n",
    "    \n",
    "        \n",
    "\n",
    "# (Xtrain,ytrain),(Xval,yval)=tran_val_split(X_train_clean,y_train_clean)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain,Xval,ytrain,yval=train_test_split(X_train,y_train,test_size=0.1)\n",
    "Xtrain,ytrain=Preprocess(Xtrain,ytrain)\n",
    "Xval,yval=Preprocess(Xval,yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47cb0bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_check(Y,Ypred):\n",
    "    return np.sum(np.argmax(Ypred,axis=0)==np.argmax(Y,axis=0))/Y.shape[1]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a23fda6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e1831bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=optimizers(Xtrain.shape[0],ytrain.shape[0],[32,32,32],['relu','relu','relu'],\n",
    "           loss='cross-entropy',optimizer='adam',\n",
    "           lamdba=0,batch_size=32,epochs=10,eta=1e-3)\n",
    "# opt.run((Xtrain,ytrain),(Xval,yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5aba965",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         3143909 function calls (3143869 primitive calls) in 7.111 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        2    0.000    0.000    7.111    3.555 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3342(run_code)\n",
      "        2    0.000    0.000    7.111    3.555 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    7.111    7.111 /tmp/ipykernel_2532984/3597795202.py:215(run)\n",
      "        1    0.000    0.000    7.111    7.111 /tmp/ipykernel_2532984/3597795202.py:109(Adam)\n",
      "        1    0.032    0.032    7.110    7.110 /tmp/ipykernel_2532984/3597795202.py:14(iterate)\n",
      "    16880    3.273    0.000    3.274    0.000 /tmp/ipykernel_2532984/3597795202.py:120(update_adam)\n",
      "    16900    0.012    0.000    1.498    0.000 /tmp/ipykernel_2532984/3033851979.py:22(forward)\n",
      "    33800    1.037    0.000    1.486    0.000 /tmp/ipykernel_2532984/1434245542.py:42(forward)\n",
      "    16880    0.463    0.000    1.318    0.000 /tmp/ipykernel_2532984/3033851979.py:29(backward)\n",
      "       10    0.000    0.000    1.289    0.129 /tmp/ipykernel_2532984/3597795202.py:35(loss_calc)\n",
      "785868/785828    0.889    0.000    1.174    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "       20    0.002    0.000    0.979    0.049 /tmp/ipykernel_2532984/1688184888.py:6(crossentropy)\n",
      "       20    0.624    0.031    0.967    0.048 /tmp/ipykernel_2532984/1688184888.py:9(<listcomp>)\n",
      "   633760    0.123    0.000    0.865    0.000 <__array_function__ internals>:177(dot)\n",
      "       20    0.000    0.000    0.309    0.015 /tmp/ipykernel_2532984/3033851979.py:54(predict)\n",
      "    16900    0.164    0.000    0.308    0.000 /tmp/ipykernel_2532984/1429278179.py:6(softmax)\n",
      "    50710    0.023    0.000    0.224    0.000 <__array_function__ internals>:177(sum)\n",
      "    67610    0.053    0.000    0.192    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/numpy/core/fromnumeric.py:69(_wrapreduction)\n",
      "    50710    0.033    0.000    0.181    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2162(sum)\n",
      "    33780    0.014    0.000    0.161    0.000 <__array_function__ internals>:177(where)\n",
      "    16900    0.036    0.000    0.141    0.000 /tmp/ipykernel_2532984/1429278179.py:9(relu)\n",
      "    67610    0.114    0.000    0.114    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "    16880    0.024    0.000    0.082    0.000 /tmp/ipykernel_2532984/2210517000.py:11(relu_d)\n",
      "    16900    0.009    0.000    0.079    0.000 <__array_function__ internals>:177(amax)\n",
      "    50640    0.016    0.000    0.073    0.000 <__array_function__ internals>:177(transpose)\n",
      "    16900    0.011    0.000    0.062    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2677(amax)\n",
      "    50640    0.012    0.000    0.042    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/numpy/core/fromnumeric.py:601(transpose)\n",
      "   633760    0.031    0.000    0.031    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/numpy/core/multiarray.py:736(dot)\n",
      "    50640    0.017    0.000    0.029    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/numpy/core/fromnumeric.py:51(_wrapfunc)\n",
      "    16880    0.029    0.000    0.029    0.000 /tmp/ipykernel_2532984/3229988252.py:29(crossentropy_d)\n",
      "    67610    0.020    0.000    0.020    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/numpy/core/fromnumeric.py:70(<dictcomp>)\n",
      "    50640    0.007    0.000    0.007    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
      "    50771    0.007    0.000    0.007    0.000 {built-in method builtins.isinstance}\n",
      "       11    0.000    0.000    0.006    0.001 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:1174(__iter__)\n",
      "       12    0.000    0.000    0.006    0.001 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:1478(display)\n",
      "       11    0.000    0.000    0.006    0.001 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:1339(refresh)\n",
      "       10    0.000    0.000    0.006    0.001 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:1212(update)\n",
      "    50686    0.005    0.000    0.005    0.000 {built-in method builtins.getattr}\n",
      "    50710    0.005    0.000    0.005    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2157(_sum_dispatcher)\n",
      "       12    0.000    0.000    0.005    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:348(print_status)\n",
      "    67610    0.005    0.000    0.005    0.000 {method 'items' of 'dict' objects}\n",
      "       14    0.000    0.000    0.005    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/ipykernel/iostream.py:463(flush)\n",
      "       26    0.000    0.000    0.005    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/utils.py:143(inner)\n",
      "       12    0.000    0.000    0.005    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:342(fp_write)\n",
      "       15    0.000    0.000    0.005    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/threading.py:589(wait)\n",
      "       15    0.000    0.000    0.005    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/threading.py:288(wait)\n",
      "    50640    0.005    0.000    0.005    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/numpy/core/fromnumeric.py:597(_transpose_dispatcher)\n",
      "      115    0.004    0.000    0.004    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "    33780    0.004    0.000    0.004    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/numpy/core/multiarray.py:341(where)\n",
      "    33821    0.003    0.000    0.003    0.000 {built-in method builtins.len}\n",
      "    16900    0.002    0.000    0.002    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2672(_amax_dispatcher)\n",
      "       12    0.000    0.000    0.001    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:1164(__str__)\n",
      "       12    0.000    0.000    0.001    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:355(format_meter)\n",
      "        1    0.000    0.000    0.001    0.001 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:846(__init__)\n",
      "       36    0.000    0.000    0.001    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/utils.py:333(disp_len)\n",
      "       36    0.000    0.000    0.001    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/utils.py:329(_text_width)\n",
      "       36    0.000    0.000    0.001    0.000 {built-in method builtins.sum}\n",
      "        1    0.000    0.000    0.001    0.001 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:329(status_printer)\n",
      "       41    0.000    0.000    0.001    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/ipykernel/iostream.py:202(schedule)\n",
      "     3342    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/utils.py:330(<genexpr>)\n",
      "       14    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/ipykernel/iostream.py:518(write)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:560(__new__)\n",
      "       20    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(hstack)\n",
      "       14    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/ipykernel/iostream.py:448(_schedule_flush)\n",
      "        2    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:1279(close)\n",
      "       41    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/zmq/sugar/socket.py:545(send)\n",
      "       20    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/numpy/core/shape_base.py:285(hstack)\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/_monitor.py:30(__init__)\n",
      "       12    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/utils.py:341(disp_trim)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/threading.py:916(start)\n",
      "       10    0.000    0.000    0.000    0.000 /tmp/ipykernel_2532984/3597795202.py:36(<listcomp>)\n",
      "       20    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(concatenate)\n",
      "       16    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/threading.py:545(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 /tmp/ipykernel_2532984/3597795202.py:116(<listcomp>)\n",
      "       93    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "       16    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/threading.py:236(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:657(get_lock)\n",
      "        1    0.000    0.000    0.000    0.000 /tmp/ipykernel_2532984/3597795202.py:115(<listcomp>)\n",
      "     3306    0.000    0.000    0.000    0.000 {built-in method unicodedata.east_asian_width}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:92(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:118(create_mp_lock)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/multiprocessing/context.py:70(RLock)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/multiprocessing/synchronize.py:186(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/multiprocessing/synchronize.py:50(__init__)\n",
      "       20    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(atleast_1d)\n",
      "       55    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/threading.py:1169(is_alive)\n",
      "       23    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:288(format_interval)\n",
      "       20    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/numpy/core/shape_base.py:23(atleast_1d)\n",
      "       61    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:233(__call__)\n",
      "       18    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(shape)\n",
      "       11    0.000    0.000    0.000    0.000 {built-in method now}\n",
      "       12    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:1460(format_dict)\n",
      "       24    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/utils.py:222(_is_ascii)\n",
      "       15    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:104(acquire)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        2    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:1300(fp_write)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/joblib/externals/loky/backend/__init__.py:7(_make_name)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/tempfile.py:153(__next__)\n",
      "       12    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:188(__format__)\n",
      "       20    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/numpy/core/shape_base.py:218(_vhstack_dispatcher)\n",
      "       55    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/threading.py:1102(_wait_for_tstate_lock)\n",
      "       15    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:108(release)\n",
      "        2    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/codeop.py:117(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _thread.start_new_thread}\n",
      "       14    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/ipykernel/iostream.py:429(_is_master_process)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n",
      "       36    0.000    0.000    0.000    0.000 {method 'sub' of 're.Pattern' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/tempfile.py:142(rng)\n",
      "       41    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/ipykernel/iostream.py:90(_event_pipe)\n",
      "       12    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:155(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:583(_decr_instances)\n",
      "       20    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/numpy/core/shape_base.py:207(_arrays_for_stack_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/utils.py:282(_screen_shape_linux)\n",
      "       15    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/threading.py:276(_acquire_restore)\n",
      "       50    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "       18    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/numpy/core/fromnumeric.py:1965(shape)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/_weakrefset.py:63(__iter__)\n",
      "       15    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/threading.py:1430(current_thread)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:576(_get_free_pos)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/threading.py:827(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:112(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/random.py:119(__init__)\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/random.py:128(seed)\n",
      "      252    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:579(<setcomp>)\n",
      "       60    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "       24    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "       15    0.000    0.000    0.000    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}\n",
      "       15    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/threading.py:267(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/utils.py:162(__init__)\n",
      "       15    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/threading.py:264(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 {function Random.seed at 0x7f0b176bc940}\n",
      "       42    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/multiprocessing/util.py:171(register_after_fork)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/random.py:506(choices)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method fcntl.ioctl}\n",
      "       16    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
      "       15    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/threading.py:279(_is_owned)\n",
      "       31    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "       40    0.000    0.000    0.000    0.000 {built-in method numpy.asanyarray}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/_weakrefset.py:111(remove)\n",
      "       57    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/threading.py:553(is_set)\n",
      "       18    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/numpy/core/fromnumeric.py:1961(_shape_dispatcher)\n",
      "       12    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:169(colour)\n",
      "       12    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/utils.py:57(__init__)\n",
      "       28    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/threading.py:1145(ident)\n",
      "       14    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "       58    0.000    0.000    0.000    0.000 {built-in method builtins.divmod}\n",
      "        2    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/_weakrefset.py:27(__exit__)\n",
      "        4    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:115(__exit__)\n",
      "       15    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/threading.py:273(_release_save)\n",
      "        2    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/contextlib.py:279(helper)\n",
      "       12    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/weakref.py:165(__setitem__)\n",
      "       15    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}\n",
      "       56    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/random.py:519(<listcomp>)\n",
      "       20    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/numpy/core/multiarray.py:148(concatenate)\n",
      "        2    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/contextlib.py:130(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/contextlib.py:102(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/traitlets/traitlets.py:675(__get__)\n",
      "       15    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/_weakrefset.py:86(add)\n",
      "       20    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/numpy/core/shape_base.py:19(_atleast_1d_dispatcher)\n",
      "       12    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/utils.py:61(__format__)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/utils.py:215(_supports_unicode)\n",
      "        2    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/_weakrefset.py:53(_commit_removals)\n",
      "        1    0.000    0.000    0.000    0.000 /tmp/ipykernel_2532984/3597795202.py:117(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 /tmp/ipykernel_2532984/2229485157.py:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/contextlib.py:139(__exit__)\n",
      "       14    0.000    0.000    0.000    0.000 {built-in method builtins.abs}\n",
      "        4    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/IPython/core/compilerop.py:174(extra_flags)\n",
      "       15    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
      "       16    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/traitlets/traitlets.py:643(get)\n",
      "        2    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/_weakrefset.py:21(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/utils.py:136(disable_on_exception)\n",
      "        1    0.000    0.000    0.000    0.000 /tmp/ipykernel_2532984/3597795202.py:118(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/utils.py:105(__init__)\n",
      "       15    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/utils.py:74(__eq__)\n",
      "       12    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:165(colour)\n",
      "       15    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1053(_handle_fromlist)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/weakref.py:348(__new__)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/utils.py:101(wrapper_setattr)\n",
      "        2    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/utils.py:171(__eq__)\n",
      "       15    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/utils.py:201(_is_utf)\n",
      "        2    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3294(compare)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:404(parent)\n",
      "        2    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/_weakrefset.py:17(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:228(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:1171(__hash__)\n",
      "        2    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/utils.py:88(__getattr__)\n",
      "        2    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py:1196(user_global_ns)\n",
      "        2    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:1167(_comparable)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/threading.py:1301(_make_invoke_excepthook)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/multiprocessing/context.py:237(get_context)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'random' of '_random.Random' objects}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method math.floor}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/multiprocessing/synchronize.py:90(_make_methods)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/weakref.py:353(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/threading.py:782(_newname)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/ipykernel/iostream.py:304(fileno)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method utcfromtimestamp}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/multiprocessing/util.py:48(debug)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/threading.py:1198(daemon)\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:1161(__del__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x7464a0}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/utils.py:231(_screen_shape_wrapper)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _weakref.proxy}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/threading.py:1183(daemon)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'difference' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:100(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/multiprocessing/context.py:197(get_start_method)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /opt/anaconda/envs/shared_conda_env/lib/python3.10/site-packages/tqdm/std.py:1315(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method atexit.register}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile, pstats, io\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "# ... do something ...\n",
    "opt.run((Xtrain,ytrain),(Xval,yval))\n",
    "# ... do something ...\n",
    "\n",
    "pr.disable()\n",
    "s = io.StringIO()\n",
    "sortby = 'cumulative'\n",
    "ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
    "ps.print_stats()\n",
    "print(s.getvalue())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
